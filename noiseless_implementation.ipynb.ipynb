{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_EDpbCJ8kSm"
      },
      "source": [
        "Erivan INAN, Sarah OUAHAB, Sheïma MEBARKA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-6mG3uP8kSs"
      },
      "source": [
        "## Méthodes de simulation pour les modèles génératifs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv3NiLRH8kSu"
      },
      "source": [
        "Ce notebook a pour but l'implémentation (partielle et simplifiée) du papier ***``Diffusion guidée de Monte Carlo pour les problèmes inverses\n",
        "linéaires bayésiens``*** (2023) par Gabriel Cardoso, Yazid Janati El Idrissi, Sylvain Le Corff et Eric Moulines.\n",
        "\n",
        "DOI : 10.48550/arXiv.2308.07983\n",
        "https://arxiv.org/abs/2308.07983\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqEuwYb68kSv"
      },
      "source": [
        "### <font color=darkred> Contexte du papier </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2s4VqJa8kSw"
      },
      "source": [
        "L’article traite des problèmes inverses linéaires mal posés dans un cadre bayésien."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jWUpATk8kSw"
      },
      "source": [
        "Le but du papier est de résoudre des problèmes inverses linéaires bayésiens de la forme :\n",
        "\n",
        "$$ y = Ax + \\sigma_{y} \\varepsilon $$\n",
        "\n",
        "où :\n",
        "- $y$ est l'observation bruitée\n",
        "- $x$ est la variable à reconstruire\n",
        "- $A$ une matrice de projection\n",
        "- $\\varepsilon \\sim \\mathcal{N}(0, I)$ la perturbation aléatoire agissant sur les pixels de $y$\n",
        "- $\\sigma_{y}$ le facteur de bruit ajouté à $y$\n",
        "\n",
        "Dans ce cadre, l'objectif consiste à retrouver l'image $x$ à partir de l'observation bruitée $y$.\n",
        "\n",
        "Une difficulté réside dans la **non-unicité** de $x$. En effet, plusieurs $x$ peuvent donner un même $y$. Egalement, on fait face à une **instabilité**, car les petites erreurs sur $y$ peuvent induire de grandes erreurs sur $x$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idOChsNa8kSw"
      },
      "source": [
        "#### Exemples d'application et types de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ubaZ7O38kSw"
      },
      "source": [
        "**Applications :**\n",
        "\n",
        "- Imagerie médicale : En IRM ou scanner, on n’observe pas directement l’image, mais des projections linéaires.\n",
        "- Photographie computationnelle : On tente de restaurer une image floue ou basse - - Restauration d’images : Défloutage, inpainting (compléter une image partiellement masquée), super-résolution.\n",
        "\n",
        "**Types de données :**\n",
        "\n",
        "La plupart des applications se basent sur des images, mais on peut également exploiter ce problème pour les signaux, notamment audio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE0hz5118kSx"
      },
      "source": [
        "#### Quelques définitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96QG4mWD8kSx"
      },
      "source": [
        "**Problème inverse linéaire** :\n",
        "On dit qu'un problème inverse est linéaire lorsque l'opérateur $A$ définit dans l'équation ci-dessus est linéaire.\n",
        "\n",
        "**Problème inverse bayésien** : Le point de vue bayésien consiste à modéliser $x$ comme une variable aléatoire ayant une loi a priori et à utiliser les données $y$ pour obtenir une loi a posteriori de $x$, notée $p(x|y)$, à l'aide de la formule de Bayes :\n",
        "\n",
        "$$ p(x|y) \\propto p(y|x) \\cdot p(x) $$\n",
        "\n",
        "où :\n",
        "- $p(x)$ est le prior (connaissance initiale sur $x$)\n",
        "- $p(y|x)$ la vraisemblance (probabilité d'observer $y$ si $x$ est donné)\n",
        "- $p(x|y)$ la loi a posteriori\n",
        "\n",
        "L'avantage d'une telle formulation est qu'elle fournit non seulement une estimation de $x$, mais également une **incertitude** sur cette estimation.\n",
        "\n",
        "**Problème bien posé** :\n",
        "On dit qu'un problème inverse est bien posé au sens d'Hadamard, si et seulement si il satisfait les deux conditions suivantes :\n",
        "- Quelle que soit la donnée initiale (ici $x$), le problème admet une unique solution $f(x)$.\n",
        "- $f : \\mathbb{R}^M \\to \\mathbb{R}^N$ est continue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qatah_lB8kSx"
      },
      "source": [
        "#### Retour à notre cadre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2cY05dL8kSx"
      },
      "source": [
        "Dans le cas du problème d'inversion directe, celui-ci est bien posé si et seulement si $A$ est inversible, puisqu'alors $x \\mapsto A^{-1}y$ est continue car on est en dimension finie.\n",
        "\n",
        "Comme en pratique on ne sait pas si $A$ est carée, ni inversible, on ne peut pas procéder à une inversion directe. On cherche alors $x \\in \\mathbb{R}^N$ tel que $Ax$ et $y$ soient proches. Les moindres carrés consistent à résoudre : $\\underset{x \\in \\mathbb{R}^N}{\\arg\\min} \\, \\left\\| Ax - y \\right\\|_2^2$\n",
        "\n",
        "Or, la solution à ce problème \"explose\" souvent, alors on ajoute une régularisation.\n",
        "\n",
        "On s'intéresse donc à :\n",
        "\n",
        "$$\\underset{x \\in \\mathbb{R}^N}{\\arg\\min} \\left( \\left\\| Ax - y \\right\\|_2^2 +  Reg(x) \\right)$$\n",
        "\n",
        "où $ x \\mapsto Reg(x)$ est une est une fonction de régularisation qui pénalise les images non satisfaisantes (par exemple les images très irrégulières, images dont les valeurs explosent, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBXF9gWn8kSx"
      },
      "source": [
        "Les limites des approches existantes dans la littérature avant ce papier incluent, mais ne se limitent pas à :\n",
        "- Un choix de fonction de régularisation difficile, car elle doit refléter les propriétés de x, et qui pourtant, a une grande influence sur la reconstruction.\n",
        "- Pas d’information sur l’incertitude de la solution.\n",
        "- Ne fournit qu’une seule solution point-estimée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb9OkYdF8kSx"
      },
      "source": [
        "### <font color=darkred> Description de la méthode </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV9bkerL8kSx"
      },
      "source": [
        "<font color=darkblue> *Nous avons choisi de nous concentrer dans ce notebook sur le cas sans bruit. Dans la suite, nous allons décrire cette méthode et l'implémenter.* </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8mAjfkV8kSy"
      },
      "source": [
        "<u>Cas sans bruit</u> (sur l'observation), c'est-à-dire qu'on suppose l'observation comme exacte $\\sigma_y =0$ :\n",
        "\n",
        "On observe exactement les $dy$ premières coordonnées <u>x</u> de $X$ (avec $X = $ <u>x</u> + $\\bar{x}$), ce qui simplifie le problème en inférant la loi postérieure sur $\\bar{x}$, les $dx - dy$ états latents restants, sachant $y$.\n",
        "\n",
        "Dans ce cas, on a une égalité stricte $y=Ax$ et seules les valeurs de $x$ la vérifiant sont compatibles avec l'observation. On peut donc voir la fonction de vraisemblance $p(y|x)$ comme une fonction de Dirac : $$p(y|x) = \\mathbb{1}_{\\{Ax = y\\}}$$\n",
        "\n",
        "\n",
        "\n",
        "Le papier fournit le pseudo-code de l'algorithme $\\texttt{MCGdiff}$ suivant, que nous allons tenter d'implémenter dans la partie suivante :\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBcbx7pD8kSy"
      },
      "source": [
        "On connait les $d_y$ premières coordonnées de $X$, on veut inférer la loi postérieure $\\phi_0^y(\\underline{x_0})$ sur les variables latentes de $X$ (variables restantes) sachant $y$.\n",
        "\n",
        "L'échantillonnage a cette forme intégrale :\n",
        "\n",
        "$$\n",
        "\\phi_0^y(\\underline{x_0}) \\propto \\int g_1^y(x_1)^{-1} \\, \\overline{p}_0(y \\mid \\overline{x}_1) \\, \\underline{p}_0(\\underline{x}_0 \\mid x_1) \\, \\phi_1^y(dx_1)\n",
        "$$\n",
        "\n",
        "où :\n",
        "- $\\underline{x_0}$ est la partie inconnue de l'état $X$ et $y$ la partie observée.\n",
        "- $\\phi_0^y(\\underline{x_0})$ est la densité cible au temps initial $t=0$\n",
        "- $\\underline{x_0}$ est le premier état de l'échantillon incomplet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPKwF5mv8kSy"
      },
      "source": [
        "Pour échantilloner, on utilise l'algo $\\texttt{SMC}$ (Sequential Monte Carlo) permettant de mettre à jour de manière itérative les $N$ échantillons aléatoires (appelés particules) pour approximer la distribution à postériori $p(x|y)$.\n",
        "\n",
        "Concrètement, on veut échantillonner la distribution $\\phi_0^y(\\underline{x_0})$ mais elle est trop compliquée pour qu'on puisse la tirer directement, alors on crée un chemin de distributions intermédiaires :\n",
        "\n",
        "$$ \\phi_n^y \\rightarrow \\phi_{n-1}^y \\rightarrow ... \\rightarrow \\phi_0^y$$\n",
        "\n",
        "où :\n",
        "\n",
        "- $\\phi_n^y$ est simple à échantillonner, par exemple gaussienne\n",
        "- $ \\phi_0^y$ la loi postérieure cible\n",
        "\n",
        "L'algorithme $\\texttt{MCGdiff}$ repose sur un échantillonnage séquentiel de Monte Carlo ($\\texttt{SMC}$) dans le sens backward du temps, c’est-à-dire du temps final $t=n$ (où la distribution est simple) vers le temps initial $t=0$ (où l’on souhaite approximer la postérieure).\n",
        "\n",
        "**1) On initialise les particules à l'instant final $s=n$**\n",
        "\n",
        "Pour initialiser les particules à l’instant final $n$, on génère des échantillons à partir de la distribution $\\phi_n^y$ à l’aide d’un mécanisme guidé par l’observation $y$. Cette étape combine l’information observée et du bruit aléatoire pour produire des particules réalistes, selon la formule suivante :\n",
        "\n",
        "$$\n",
        "\\overline{\\xi}_n^i = K_n \\bar{\\alpha}_n^{1/2} y + (1 - \\bar{\\alpha}_n) K_n \\bar{z}_n^i,\\quad\n",
        "\\xi_n^i = \\overline{\\xi}_n^i {}^{\\mathbin{\\frown}} \\underline{z}_n^i\n",
        "$$\n",
        "\n",
        "où $\\overline{z}_n^i \\sim \\mathcal{N}(0_{d_y}, I{d_y}) \\hspace{5pt} \\text{et} \\hspace{5pt} \\underline{z}_n^i \\sim \\mathcal{N}(0_{I_{d_x - d_y}}, I_{d_x - d_y})$.\n",
        "\n",
        "L'ensemble de particules $\\xi_n^i$ proches de la projection $K_n$ est initialisé."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgDcLPCM8kSy"
      },
      "source": [
        "**2) Propagation backward des particules de $s=n-1$ jusqu'à $s=0$**\n",
        "\n",
        "la phase backward consiste à remonter progressivement de l’état final $x_n$ vers l’état initial $x_0$, en construisant à chaque étape une approximation de la distribution conditionnelle $p(x_s|y)$. Ce processus repose sur la méthode d’échantillonnage séquentielle $\\texttt{SMC}$ : on commence par initialiser des particules à l'étape $s=n$, proches de l'observation $y$, puis on remonte pas à pas (de $s=n−1$ à $s=0$).\n",
        "\n",
        "**Calcul des poids d’importance**\n",
        "\n",
        "A chaque étape, on pondère les particules selon leur cohérence avec l'observation $y$ via des poids.\n",
        "\n",
        "- Si $s=n-1$ (cas terminal), le poids est $ \\widetilde{\\omega}_{n-1}^i (\\xi_n^i) = \\mathcal{N}( \\overline{\\alpha}^{1/2}y ; \\overline{\\text{m}}_n(\\xi_{s+1}^i), 2- \\overline{\\alpha}_n)$\n",
        "\n",
        "- Sinon (cas intermédiaire), le calcul des poids se fait selon la formule :\n",
        "\n",
        "$$ \\frac{ \\mathcal{N}( \\overline{\\alpha}^{1/2}y ; \\overline{\\text{m}}_{s+1}(\\xi_{s+1}^i), \\sigma_{s+1}^2 , 1- \\overline{\\alpha}_n) }{ \\mathcal{N}( \\overline{\\alpha}_{s+1}^{1/2}y ; \\overline{\\xi}_{s+1}^i, 1 - \\overline{\\alpha}_{s+1}}) $$\n",
        "\n",
        "Une fois les poids d'importance calculés pour toutes les particules à l’étape $s+1$, on effectue un rééchantillonnage.\n",
        "\n",
        "**Rééchantillonnage multinomial**\n",
        "\n",
        "Chaque particule $s$ va être va être engendrée à partir d’une particule \"parente\" $\\xi_{s+1}^{I_{s+1}^i}$ au hasard parmi les $\\xi_{s+1}^j$ avec une probabilité conditionnelle à leur poids. C'est un échantillonnage multinomial, où l'on tire $N$ fois dans une loi catégorielle discrète : $ \\text{Cat}\\left(\\left\\{ \\tilde{\\omega}_s\\left(\\xi_{s+1}^j\\right) \\middle/ \\sum_{k=1}^N \\tilde{\\omega}_s\\left(\\xi_{s+1}^k\\right) \\right\\}_{j=1}^N\\right) $. Cela permet de concentrer les particules sur les zones de forte probabilité de la distribution cible.\n",
        "\n",
        "Une fois l’ancêtre $\\xi_{s+1}^{I_{s+1}^i}$ sélectionné, on génère un nouvel échantillon intermédiaire $\\overline{\\xi}_s^i$, qui combine l'observation $y$, un bruit $\\overline{z}_s^i \\sim \\mathcal{N}(O_{d_s}, I_{d_s})$.\n",
        "\n",
        "**Mise à jour des particules à l'instant $s$**\n",
        "\n",
        "On met à jour les particules à l'instant $s$ via la formule :\n",
        "\n",
        "$$ \\bar{\\xi}_s^i = K_s \\bar{\\alpha}_s^{1/2} y + (1 - K_s) \\overline{m}_{s+1}(\\xi_{s+1}^i) + (1 - \\alpha_s)^{1/2} K_s^{1/2} \\bar{z}_s^i,\\quad\n",
        "\\underline{\\xi}_s^i = \\underline{m}_{s+1}(\\xi_{s+1}^i) + \\sigma_{s+1} \\underline{z}_s^i\n",
        "$$\n",
        "\n",
        "**Particule complétée**\n",
        "\n",
        "On concatène les deux parties pour obtenir la nouvelle particule à l'instant $s$ : $ \\xi_n^i = \\underline{\\xi}_s^i {}^{\\mathbin{\\frown}} \\overline{\\xi}_s^i$.\n",
        "\n",
        "Cette étape simule une particule $\\xi_s^i$ à partir de la suivante $\\xi_{s+1}^i$, en combinant :\n",
        "\n",
        "- l'information observée $y$,\n",
        "- la guidance par le score prior via $m_{s+1}$,\n",
        "- le bruit aléatoire pour conserver la diversité.\n",
        "\n",
        "Elle permet de remonter le processus de diffusion de façon informée par les données et le modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU1L3dwn8kSy"
      },
      "source": [
        "<font color=darkblue> *Bien que nous n'ayons pas eu pour objectif l'implémentation du cas sans bruit, nous fournissons quand même cette explication du cas sans bruit, qui constitue l'une des différences principale avec le cas sans bruit.* </font>\n",
        "\n",
        "<u>Cas avec bruit</u> (sur l'observation) avec une intensité de bruit $\\sigma_y >0$, c'est-à-dire que l'observation est incertaine, c'est l'instance bruitée d’un processus aléatoire :\n",
        "\n",
        "L'observation $y$ est bruitée, donc même si on connaît $x$, l'observation $y$ peut varier un peu à cause du bruit. $y$ suit une loi gaussienne centrée en $Ax$ donc la densité de vraisemblance est $p(y|x) = \\mathcal{N}(y; Ax, \\sigma_{y}^{2} I_{d_{y}})$. La vraisemblance $p(y|x)$ est donc élevée si $y$ est proche de $Ax$ et faible si $y$ est loin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLNw2y7q8kSy"
      },
      "source": [
        "### <font color=darkred> Limites des approches existantes dans la littérature et Contributions de ce papier pour y répondre : </font> l'algorithme $\\texttt{MCGdiff}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXvL-niK8kSy"
      },
      "source": [
        "<font color=darkblue> *Dans cette section, nous tâchons de lister les limites des approches existantes dans la littérature avant la publication de ce papier, puis pour chacune des limites, expliquer la contribution apportée dans ce papier pour pallier à la limite associée.*\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HcY0Vv-8kSy"
      },
      "source": [
        "- La littérature se concentrant sur l'optimisation de fonctions de régularisations ne permet certe de fournir une estimation, mais on ne sait pas combien on peut lui faire confiance.\n",
        "\n",
        "$\\to$ Le papier propose une approche bayésienne, dans laquelle on adopte un point de vue probabiliste : on médilise l'incertitude sur $x$ avec une loi a priori $p(x)$. La formulation bayésienne fournit non seulement une estimation de $x$, mais également une **incertitude** sur cette estimation. Elle permet également d'estimer l'ensemble des solutions probables et non pas juste une seule.\n",
        "\n",
        "- Le problème est mal posé (non-unicité de la solution, instabilité car grands variations dans la reconstruction de $x$ dues à de petites perturbations sur $y$), d'où le besoin de priors puissants.\n",
        "\n",
        "$\\to$ Les auteurs proposent d'utiliser un modèle de diffusion comme prior pour échantilloner la loi posterior $p(x|y)$.\n",
        "\n",
        "En particulier, les *score-based generative models* $\\texttt{SGM}$. Ces modèles permettent de générer des échantillons réalistes à partir de bruit en inversant un processus de diffusion montrant une grande efficacité pour servir de priors dans les problèmes inverses bayésiens.\n",
        "\n",
        "Cette approche par *score-based generative models* comprend bien des avantages : au delà de l'absence de nécéssité d'entraînement spécifique par tâche (défloutage, inpainting, super-resolution, etc), est son indépendance avec le problème inverse initial. C'est-à-dire que ce prior est appris au préalable, de manière non supervisée, sur les données de type $x$ du dataset.\n",
        "\n",
        "De plus, ces modèles $\\texttt{SGM}$ ne nécessitent pas de modéliser explicitement la densité $p(x)$. Ils apprennent directement son gradient logarithmique, qu'on appelle $\\texttt{score}$ :\n",
        "\n",
        "- Les précédentes approches dans la littérature $(\\texttt{DDPM, score SDE})$ imposaient des hypothèses particulièrement fortes sur la coïncidence des lois jointes des processus avant $p$ et la loi de transition arrière $q$ :\n",
        "\n",
        "$$ p_t(x_t) \\hspace{2pt} q_{t+1}(x_{t+1}|x_t) = p_{t+1}(x_{t+1}) \\hspace{2pt} p_t(x_t|x_{t+1}) \\hspace{10pt} \\forall t \\in [0: n-1] $$\n",
        "\n",
        " Or, ce n'est pas le cas dans des contextes réalistes. En effet, la loi conditionnelle backward $p_t(x_t|x_{t+1})$ est en général inconnue. $q_t$ la loi de transition backward non plus.\n",
        "\n",
        "$\\to$ L'algorithme $\\texttt{MCGdiff}$ permet de s'aquitter de cette hypothèse forte tout en fournissant une solution cohérente sans hypothèse restrictive.\n",
        "\n",
        "De plus, dans les modèles basés sur la log-vraisemblance *likelihood-based models*, la méthode consistait en la modélisation directe de la densité de probabilité comme suit :\n",
        "\n",
        "$$ p_\\theta(x) = \\frac{\\mathrm{e}^{-f_\\theta(x)}}{Z_\\theta} $$\n",
        "\n",
        "où :\n",
        "\n",
        "- $f_\\theta$ est une fonction à valeurs réelles paramétrée par un paramètre inconnu\n",
        "- $\\theta$, entraîné à partir du jeu de données\n",
        "- $Z_\\theta$ est une constante de normalisation\n",
        "\n",
        "$Z_\\theta$ est une \"partition function\" représentée par une intégrale sur tout l'espace des données, très grand dans le cadre d'un dataset d'images. Celle-ci permet de normaliser la fonction $\\mathrm{e}^{-f_\\theta(x)}$ pour en faire une densité de probabilité :\n",
        "\n",
        "$$ Z_{\\theta} = \\int e^{-f_{\\theta}(x)}\\, dx \\quad \\text{et donc} \\quad \\int p_{\\theta}(x)\\, dx = 1 $$\n",
        "\n",
        "Or, l'intégrale $Z_{\\theta}$ n'a pas de solution fermée dans la majorité des cas, mais pour entraîner $p_{\\theta}(x)$, il faudrait idéalement connaître $Z_\\theta$.\n",
        "\n",
        "$\\to$ Les auteurs proposent l'algorithme d'échantillonnage $\\texttt{SMC}$, permettant d'échantillonner des particules selon $p_\\theta(x)$, sans la connaissance de $Z_\\theta$.\n",
        "\n",
        "\n",
        "\n",
        "Une approximation $q_t(x_t | x_{t+1})$ est choisie pour modéliser la transition entre deux instants du processus de diffusion dans le sens inverse du temps. Cette transition stochastique est construite à partir :\n",
        "\n",
        "- du point $x_{t+1}$\n",
        "- du score $s_t(x_{t+1}) = \\nabla \\text{log} \\hspace{2pt} p_t(x_{t+1})$\n",
        "- d'un bruit gaussien centré autour de $ x_{t+1} + \\sigma_{t}^{2} \\dot \\nabla \\text{log} p_t(x_{t+1})$ avec une variance isotrope $\\sigma_{t}^{2} I$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-JvhxS98kSz"
      },
      "source": [
        "En effet, dans les *score-based approach*, on modélise directement la fonction de score suivante :\n",
        "\n",
        "$$\n",
        "s_\\theta(x) = \\nabla_x \\log p_\\theta(x)\\,.\n",
        "$$\n",
        "\n",
        "C'est très pratique car cette quantité ne dépend pas de $Z_\\theta$ comme $\\nabla_x \\log p_\\theta(x) = - \\nabla_x f_\\theta(x)$.\n",
        "Le score peut donc être paramétrisé sans se soucier de la constante de normalisation $Z_\\theta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtCCMvuR8kSz"
      },
      "source": [
        "Une fois cette approximation $q_t(x_t | x_{t+1})$ définie, l’algorithme MCGdiff échantillonne une population de particules backward à l’aide de cette transition, et corrige l’erreur d’approximation par un mécanisme d’importance sampling.\n",
        "\n",
        "Ainsi, à chaque étape $t$, on :\n",
        "\n",
        "- Évalue la vraisemblance de chaque particule propagée selon l’observation $y$ et la structure du modèle backward,\n",
        "- Calcule des poids d’importance non normalisés $\\widetilde{\\omega}_t^i$,\n",
        "- Applique un rééchantillonnage multinomial selon ces poids pour sélectionner les ancêtres les plus cohérents avec la distribution cible.\n",
        "\n",
        "Ce mécanisme permet à $\\texttt{MCGdiff}$ :\n",
        "\n",
        "de simuler des trajectoires backward cohérentes même si $p_t(x_t|x_{t+1})$ est inconnu, et d’approcher la postérieure $p(x|y)$ au lieu de simplement générer des échantillons réalistes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MECEEHz48kSz"
      },
      "source": [
        "- Les algorithmes existants dans la littérature ne garantissent pas formellement une cohérence pour l’échantillonnage conditionnel basé sur des modèles de diffusion.\n",
        "\n",
        "$\\to$ Sous des des hypothèses raisonnables, les auteurs démontrent que la distribution empirique des échantillons produits par MCGdiff converge vers la distribution a posteriori cible, lorsque le nombre de particules tend vers l’infini.\n",
        "\n",
        "- De plus, les approches dans la littérature ne fournissent pas d'expériences numériques sur plusieurs cas où la loi posterior est connue.\n",
        "\n",
        "$\\to$ Les auteurs valident leurs résultats théoriques en générant des echantillons concentrés sur le support réel de la postérieure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0x71VDm8kSz"
      },
      "source": [
        "**$\\to$ Ainsi, l'algortihme $\\texttt{MCGdiff}$ proposé par les auteurs combine :**\n",
        "- Le score-based prior, appris au préalable de manière non supervisée,\n",
        "- Une méthode Monte Carlo séquentielle $\\texttt{SMC}$ pour produire des échantillons de la posterior $p(x|y)$ de manière guidée grâce au score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmp5rWmZ8kSz"
      },
      "source": [
        "### <font color=darkred> Implémentation de l'algorithme </font> $\\texttt{MCGdiff}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNJ7Ykrf8kS0"
      },
      "source": [
        "<font color=darkblue> *Dans cette section, nous tentons d'explorer plusieurs implémentations de $\\texttt{MCGdiff}$, avec ou sans $\\texttt{SMC}$, avec ou sans structure d'autoencodeur.*\n",
        "\n",
        "Tout au long de ce notebook, notre objectif sera de reconstruire des images MNIST bruitées en suivant au plus près le schéma de reverse diffusion décrit dans le papier.\n",
        "\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54-i0Rgc8kS0"
      },
      "source": [
        "<u>Cas sans bruit</u> (sur l'observation) : On propose d'implémenter l'approche dans laquelle on néglige le bruit de mesure c'est-à-dire lorsque $\\sigma_{y}=0$. On tombe sur un problème d'inversion directe, on cherche $x$ tel que $y= Ax$.\n",
        "\n",
        "L’objectif est d’échantillonner les coordonnées manquantes de $x \\sim p_0$ conditionnellement à la partie observée $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGBC7bdA8kS0"
      },
      "source": [
        "#### <font color=darkred> Implémentation du SMC seul</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPimSMMb8kS0"
      },
      "source": [
        "Posons :\n",
        "\n",
        "- $x \\in \\mathbb{R}^{d_x}$ = variable latente\n",
        "- $y \\in \\mathbb{R}^{d_y}$ = observation\n",
        "- $\\bar{\\alpha}_t = \\prod_{s=1}^{t} (1 - \\beta_s)$\n",
        "- $\\alpha_t = 1 - \\beta_t$\n",
        "- $K_t$ : matrice de gain (dans le papier c’est un scalaire, mais on garde la matrice générale)\n",
        "\n",
        "On définit :\n",
        "- $\\vec{\\xi_t^{i}}$ : particule guidée par l’observation\n",
        "- $\\xi_t^{i}$ : particule complète\n",
        "- $m_t(x)$ : centre de transition du backward process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MYPz2DK8kS0"
      },
      "source": [
        "**Initialisation des particules à $t=n$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zih3wlFN8kS1"
      },
      "source": [
        "On veut :\n",
        "\n",
        "- tirer les $dy$ premières dimensions guidées par $y$\n",
        "- et les $dx - dy$ restantes comme bruit libre.\n",
        "\n",
        "La variable finale $\\xi_n^{i} \\in \\mathbb{R}^{dx}$ est la concaténation de ces deux parties $\\vec{\\xi_n^{i}} \\in \\mathbb{R}^{dx}$ (guidée) et $\\hat{z}_n^{i} \\in \\mathbb{R}^{dx-dy}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFtdLv1B8kS1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# On commence par initialiser les particules\n",
        "# xi_s et xi_bar_s\n",
        "\n",
        "# Initialisation des particules\n",
        "# Correspond à l'algorithme 1, lignes 1 à 4 :\n",
        "# Pour chaque particule i :\n",
        "# - on tire z_n^i ~ N(0_dy, I_dy)\n",
        "# - on calcule \\bar{ξ}_n^i = K_n sqrt(α_n) y + (1 - α_n) K_n z_n^i\n",
        "# - on tire \\hat{z}_n^i ~ N(0_dx-dy, I_dx-dy)\n",
        "# - on pose ξ_n^i = \\bar{ξ}_n^i + \\hat{z}_n^i (concaténation)\n",
        "\n",
        "def initialize_particles(N, dy, dx, alpha_n, K_n, y):\n",
        "    \"\"\"\n",
        "    Initialise les particules ξ_n selon l'algorithme 1 MCGdiff (σ = 0).\n",
        "\n",
        "    Args:\n",
        "        N       : nombre de particules\n",
        "        dy      : nombre de coordonnées observées (dim de y)\n",
        "        dx      : dimension totale\n",
        "        alpha_n : coefficient d'atténuation (alpha_n = 1 - β_n)\n",
        "        K_n     : matrice de gain (matrice dx x dy)\n",
        "        y       : observation de dimension dy\n",
        "\n",
        "    Returns:\n",
        "        xi_n (N x dx) : particules complètes à l'instant n\n",
        "        xi_bar_n (N x dy) : partie observée conditionnée de chaque particule\n",
        "    \"\"\"\n",
        "    sqrt_alpha_n = np.sqrt(alpha_n)\n",
        "    d_remain = dx - dy # dimension de coord non observés\n",
        "\n",
        "    # Matrices de particules\n",
        "    xi_n = np.zeros((N, dx))       # Particules complètes\n",
        "    xi_bar_n = np.zeros((N, dy))   # Parties observées conditionnées sur y\n",
        "\n",
        "    for i in range(N):\n",
        "        # Bruit sur la partie observée\n",
        "        z_dy = np.random.randn(dy)\n",
        "\n",
        "        # Calcul de ξ̄_n^i = K_n (√α_n y + (1 - α_n) z_dy)\n",
        "        xi_bar = K_n @ (sqrt_alpha_n * y + (1 - alpha_n) * z_dy)\n",
        "        xi_bar_n[i] = xi_bar\n",
        "\n",
        "        # Bruit sur la partie non observée\n",
        "        z_remain = np.random.randn(d_remain)\n",
        "\n",
        "        # Construction finale ξ_n^i = concat(ξ̄_n^i, z_remain)\n",
        "        xi_n[i, :dy] = xi_bar\n",
        "        xi_n[i, dy:] = z_remain\n",
        "\n",
        "    return xi_n, xi_bar_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NX47Wv98kS3",
        "outputId": "25217b0c-5a5e-4c79-c31f-c5564c847cd0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ξ_n[i] (particule complète)</th>\n",
              "      <th>ξ̄_n[i] (partie observée)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.9014218690070872, -0.5870066395126547, 0.29...</td>\n",
              "      <td>[0.9014218690070872, -0.5870066395126547, 0.29...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1.0153041294335923, -0.4758889611853043, 0.08...</td>\n",
              "      <td>[1.0153041294335923, -0.4758889611853043, 0.08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.8882982584807886, -0.38320954424339304, 0.2...</td>\n",
              "      <td>[0.8882982584807886, -0.38320954424339304, 0.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.9773368133961026, -0.5702720069174846, 0.29...</td>\n",
              "      <td>[0.9773368133961026, -0.5702720069174846, 0.29...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1.0411294677011507, -0.2762872350451256, 0.19...</td>\n",
              "      <td>[1.0411294677011507, -0.2762872350451256, 0.19...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         ξ_n[i] (particule complète)  \\\n",
              "0  [0.9014218690070872, -0.5870066395126547, 0.29...   \n",
              "1  [1.0153041294335923, -0.4758889611853043, 0.08...   \n",
              "2  [0.8882982584807886, -0.38320954424339304, 0.2...   \n",
              "3  [0.9773368133961026, -0.5702720069174846, 0.29...   \n",
              "4  [1.0411294677011507, -0.2762872350451256, 0.19...   \n",
              "\n",
              "                           ξ̄_n[i] (partie observée)  \n",
              "0  [0.9014218690070872, -0.5870066395126547, 0.29...  \n",
              "1  [1.0153041294335923, -0.4758889611853043, 0.08...  \n",
              "2  [0.8882982584807886, -0.38320954424339304, 0.2...  \n",
              "3  [0.9773368133961026, -0.5702720069174846, 0.29...  \n",
              "4  [1.0411294677011507, -0.2762872350451256, 0.19...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test de la fonction d'initialisation des particules\n",
        "# initialize_particles(N, dy, dx, alpha_n, K_n, y)\n",
        "\n",
        "# Paramètres\n",
        "N = 5\n",
        "dy = 3\n",
        "dx = 6\n",
        "alpha_n = 0.9\n",
        "y = np.array([1.0, -0.5, 0.2])\n",
        "\n",
        "# K_n : identité (plus simple)\n",
        "K_n = np.eye(dy)\n",
        "\n",
        "xi_n, xi_bar_n = initialize_particles(N, dy, dx, alpha_n, K_n, y)\n",
        "\n",
        "df_init = pd.DataFrame({\n",
        "    \"ξ_n[i] (particule complète)\": list(xi_n),\n",
        "    \"ξ̄_n[i] (partie observée)\": list(xi_bar_n)\n",
        "})\n",
        "\n",
        "df_init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zceszcf78kS4"
      },
      "source": [
        "**Pondération des particules à $t=n−1$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97jKzwQi8kS5"
      },
      "outputs": [],
      "source": [
        "def compute_terminal_weights(xi_n, alpha_bar_n, y, m_bar_fn, dy):\n",
        "    \"\"\"\n",
        "    Calcule les poids terminaux ω̃_{n−1} selon l'équation (2.4) du papier MCGdiff.\n",
        "\n",
        "    Args:\n",
        "        xi_n       : (N x dx) particules à l'étape n\n",
        "        alpha_bar_n: scalaire, alphā_n\n",
        "        y          : observation (dy,)\n",
        "        m_bar_fn   : fonction donnant m̄_n(x) ∈ ℝ^dy\n",
        "        dy         : dimension observée\n",
        "\n",
        "    Returns:\n",
        "        weights : (N,) poids non normalisés ω̃_{n−1}\n",
        "    \"\"\"\n",
        "    N = xi_n.shape[0]\n",
        "    weights = np.zeros(N)\n",
        "    cov = (2 - alpha_bar_n) * np.eye(dy)\n",
        "    sqrt_alpha_bar_n = np.sqrt(alpha_bar_n)\n",
        "\n",
        "    for i in range(N):\n",
        "        m_bar = m_bar_fn(xi_n[i], dy)\n",
        "        weights[i] = multivariate_normal.pdf(sqrt_alpha_bar_n * y, mean=m_bar, cov=cov)\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "def compute_intermediate_weights(xi_s, xi_bar_sp1, alpha_bar_sp1, sigma2_sp1, y, K_sp1, m_fn, m_bar_fn, dy):\n",
        "    \"\"\"\n",
        "    Calcule les poids intermédiaires ω̃_s selon l'équation (2.4) du papier MCGdiff.\n",
        "\n",
        "    Args:\n",
        "        xi_s         : (N x dx) particules à l'étape s\n",
        "        xi_bar_sp1   : (N x dx) particules observées à l'étape s+1\n",
        "        alpha_bar_sp1: scalaire, alphā_{s+1}\n",
        "        sigma2_sp1   : scalaire, σ²_{s+1}\n",
        "        y            : observation (dy,)\n",
        "        K_sp1        : matrice (dx x dy)\n",
        "        m_fn         : fonction donnant m_{s+1}(x) ∈ ℝ^dx\n",
        "        m_bar_fn     : fonction donnant m̄_{s+1}(x) ∈ ℝ^dy\n",
        "        dy           : dimension observée\n",
        "\n",
        "    Returns:\n",
        "        weights : (N,) poids non normalisés ω̃_s\n",
        "    \"\"\"\n",
        "    N, dx = xi_s.shape\n",
        "    weights = np.zeros(N)\n",
        "    sqrt_alpha_bar_sp1 = np.sqrt(alpha_bar_sp1)\n",
        "\n",
        "    cov1 = (sigma2_sp1 + 1 - alpha_bar_sp1) * np.eye(dy)\n",
        "    cov2 = sigma2_sp1 * np.eye(dx)\n",
        "    cov3 = (1 - alpha_bar_sp1) * np.eye(dx)\n",
        "\n",
        "    mean_denom = K_sp1 @ (sqrt_alpha_bar_sp1 * y)\n",
        "\n",
        "    for i in range(N):\n",
        "        m_bar = m_bar_fn(xi_s[i], dy)\n",
        "        m = m_fn(xi_s[i])\n",
        "        term1 = multivariate_normal.pdf(sqrt_alpha_bar_sp1 * y, mean=m_bar, cov=cov1)\n",
        "        term2 = multivariate_normal.pdf(xi_bar_sp1[i], mean=m, cov=cov2)\n",
        "        term3 = multivariate_normal.pdf(xi_bar_sp1[i], mean=mean_denom, cov=cov3)\n",
        "        weights[i] = term1 * term2 / term3\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmNjcmRn8kS6"
      },
      "outputs": [],
      "source": [
        "# Fonctions m(x) et m̄(x) de projection\n",
        "def m_bar_fn(x, dy):  # projette sur les dy premières coords\n",
        "    return x[:dy]\n",
        "\n",
        "def m_fn(x):  # identité ici\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpWxqjOT8kTC",
        "outputId": "d2b7024a-c875-4c2d-babd-b993532fba7f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Poids terminaux ω̃_{n−1}</th>\n",
              "      <th>Poids intermédiaires ω̃_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.091804</td>\n",
              "      <td>3.792707e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.004012</td>\n",
              "      <td>1.273924e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.078977</td>\n",
              "      <td>3.139204e-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.088142</td>\n",
              "      <td>2.069732e-28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Poids terminaux ω̃_{n−1}  Poids intermédiaires ω̃_s\n",
              "0                  0.091804               3.792707e+00\n",
              "1                  0.004012               1.273924e+03\n",
              "2                  0.078977               3.139204e-26\n",
              "3                  0.088142               2.069732e-28"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test des fonctions de calcul des poids terminaux et intermédiaires\n",
        "# compute_terminal_weights(xi_n_minus_1, alpha_n, y, m_bar_fn, dy)\n",
        "# et compute_general_weights(xi_s, xi_bar_sp1, alpha_sp1, sigma_sp1, y, K_sp1, m_fn, m_bar_fn, dy)\n",
        "\n",
        "# Paramètres\n",
        "N = 4\n",
        "dx = 5\n",
        "dy = 2\n",
        "alpha_bar_n = 0.9\n",
        "sigma2_sp1 = 0.1\n",
        "y = np.array([0.5, -1.2])\n",
        "K_sp1 = np.eye(dx)[:, :dy]  # dx x dy\n",
        "\n",
        "# Particules fictives\n",
        "np.random.seed(42)\n",
        "xi_n = np.random.randn(N, dx)\n",
        "xi_s = np.random.randn(N, dx)\n",
        "xi_bar_sp1 = np.random.randn(N, dx)\n",
        "\n",
        "# Calcul des poids\n",
        "terminal_weights = compute_terminal_weights(xi_n, alpha_bar_n, y, m_bar_fn, dy)\n",
        "intermediate_weights = compute_intermediate_weights(xi_s, xi_bar_sp1, alpha_bar_n, sigma2_sp1, y, K_sp1, m_fn, m_bar_fn, dy)\n",
        "\n",
        "# Affichage\n",
        "df_poids = pd.DataFrame({\n",
        "    \"Poids terminaux ω̃_{n−1}\": terminal_weights,\n",
        "    \"Poids intermédiaires ω̃_s\": intermediate_weights\n",
        "})\n",
        "\n",
        "df_poids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy97-SXP8kTD"
      },
      "source": [
        "**Propagation des particules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk5b2U_98kTD"
      },
      "outputs": [],
      "source": [
        "# Propagation des particules\n",
        "# Implémente l'étape de l'algorithme 1, ligne 11 :\n",
        "# ξ_s^i ← m_{s+1}(ξ_{s+1}^{I_{s+1}^i}) + σ_{s+1} z\n",
        "# Transition de Markov backward, qui sert à simuler les ξ_s à partir des ξ_{s+1}\n",
        "# Il s'agit d'une transition stochastique, on part d'un échantillon ξ_{s+1} et\n",
        "# on lui ajoute du bruit gaussien via la fonction ci-dessous.\n",
        "\n",
        "def propagate_particles(xi_sp1, alpha_bar_sp1, sigma2_sp1, y, K_sp1, score_fn):\n",
        "    \"\"\"\n",
        "    Propagation backward des particules ξ_{s+1} vers ξ_s selon le modèle MCGdiff, cas sans bruit.\n",
        "\n",
        "    Args:\n",
        "        xi_sp1        : (N x dx) particules à l'étape s+1\n",
        "        alpha_bar_sp1 : scalaire, ᾱ_{s+1}\n",
        "        sigma2_sp1    : scalaire, σ²_{s+1}\n",
        "        y             : observation (dy,)\n",
        "        K_sp1         : matrice (dx x dy)\n",
        "        score_fn      : fonction s_{s+1}(x) retournant le score (∇ log p(x)) ∈ ℝ^dx\n",
        "\n",
        "    Returns:\n",
        "        xi_s : (N x dx) particules propagées à l'étape s\n",
        "    \"\"\"\n",
        "    N, dx = xi_sp1.shape\n",
        "    dy = y.shape[0]\n",
        "    xi_s = np.zeros((N, dx))\n",
        "    sqrt_alpha_bar_sp1 = np.sqrt(alpha_bar_sp1)\n",
        "\n",
        "    for i in range(N):\n",
        "        x_sp1 = xi_sp1[i]\n",
        "\n",
        "        # Moyenne guidée\n",
        "        score = score_fn(x_sp1)                     # ∈ ℝ^dx\n",
        "        mean = x_sp1 + sigma2_sp1 * score           # m_{s+1}(x_{s+1})\n",
        "\n",
        "        # Tirage aléatoire dans le backward kernel avec guidage\n",
        "        noise = np.random.randn(dx)\n",
        "        x_s = mean + np.sqrt(sigma2_sp1) * noise    # propagation\n",
        "\n",
        "        xi_s[i] = x_s\n",
        "\n",
        "    return xi_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLHUJ5vo8kTF",
        "outputId": "f2d0163f-a703-48f0-d284-9950c6886e04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Particules ξ_n (completes)</th>\n",
              "      <th>Poids terminaux ω̃_{n−1}</th>\n",
              "      <th>Particules propagées ξ_s</th>\n",
              "      <th>Poids intermédiaires ω̃_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.9007658742659848, -0.4929075466916386, 0.07...</td>\n",
              "      <td>0.054664</td>\n",
              "      <td>[0.8413879034001064, -0.137304350602858, -0.15...</td>\n",
              "      <td>30290.106233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.9414822858924804, -0.3739883592360545, 0.22...</td>\n",
              "      <td>0.054750</td>\n",
              "      <td>[0.9409755109916504, -0.25403659778408505, 0.2...</td>\n",
              "      <td>5094.838178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.9451006941395186, -0.3178772834438563, -0.0...</td>\n",
              "      <td>0.052754</td>\n",
              "      <td>[0.7422147787827656, -0.5397919036715124, -0.1...</td>\n",
              "      <td>2.485689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.957859375704064, -0.6730985404853461, 0.167...</td>\n",
              "      <td>0.054042</td>\n",
              "      <td>[0.943518022828681, -0.6293305520686242, -0.45...</td>\n",
              "      <td>18.538153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.867833937761195, -0.5245173533837105, 0.281...</td>\n",
              "      <td>0.054601</td>\n",
              "      <td>[0.7202206658234974, -0.37670797563086655, 0.2...</td>\n",
              "      <td>1.816984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Particules ξ_n (completes)  \\\n",
              "0  [0.9007658742659848, -0.4929075466916386, 0.07...   \n",
              "1  [0.9414822858924804, -0.3739883592360545, 0.22...   \n",
              "2  [0.9451006941395186, -0.3178772834438563, -0.0...   \n",
              "3  [0.957859375704064, -0.6730985404853461, 0.167...   \n",
              "4  [0.867833937761195, -0.5245173533837105, 0.281...   \n",
              "\n",
              "   Poids terminaux ω̃_{n−1}  \\\n",
              "0                  0.054664   \n",
              "1                  0.054750   \n",
              "2                  0.052754   \n",
              "3                  0.054042   \n",
              "4                  0.054601   \n",
              "\n",
              "                            Particules propagées ξ_s  \\\n",
              "0  [0.8413879034001064, -0.137304350602858, -0.15...   \n",
              "1  [0.9409755109916504, -0.25403659778408505, 0.2...   \n",
              "2  [0.7422147787827656, -0.5397919036715124, -0.1...   \n",
              "3  [0.943518022828681, -0.6293305520686242, -0.45...   \n",
              "4  [0.7202206658234974, -0.37670797563086655, 0.2...   \n",
              "\n",
              "   Poids intermédiaires ω̃_s  \n",
              "0               30290.106233  \n",
              "1                5094.838178  \n",
              "2                   2.485689  \n",
              "3                  18.538153  \n",
              "4                   1.816984  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Paramètres du test\n",
        "N = 5\n",
        "dx = 6\n",
        "dy = 3\n",
        "alpha_bar_n = 0.9\n",
        "alpha_bar_sp1 = 0.85\n",
        "sigma2_sp1 = 0.1\n",
        "y = np.array([1.0, -0.5, 0.2])\n",
        "K_n = np.eye(dy)               # pour initialisation\n",
        "K_sp1 = np.eye(dx)[:, :dy]     # pour projection dans compute_intermediate_weights\n",
        "\n",
        "# Fonctions m, m_bar et score\n",
        "def m_bar_fn(x, dy): return x[:dy]\n",
        "def m_fn(x): return x\n",
        "def score_fn(x): return -x  # score d'une loi normale centrée\n",
        "\n",
        "# Étape 1 : initialisation des particules à l'étape n\n",
        "xi_n, xi_bar_n = initialize_particles(N, dy, dx, alpha_bar_n, K_n, y)\n",
        "\n",
        "# Étape 2 : test des poids terminaux\n",
        "terminal_weights = compute_terminal_weights(xi_n, alpha_bar_n, y, m_bar_fn, dy)\n",
        "\n",
        "# Étape 3 : propagation des particules backward : xi_{s+1} -> xi_s\n",
        "xi_sp1 = xi_n  # on part de l'étape n\n",
        "xi_s = propagate_particles(xi_sp1, alpha_bar_sp1, sigma2_sp1, y, K_sp1, score_fn)\n",
        "\n",
        "# Étape 4 : génération de xi_bar_{s+1} fictif\n",
        "xi_bar_sp1 = xi_sp1  # on suppose que xi_sp1 est connu (comme dans SMC)\n",
        "\n",
        "# Étape 5 : test des poids intermédiaires\n",
        "intermediate_weights = compute_intermediate_weights(xi_s, xi_bar_sp1, alpha_bar_sp1, sigma2_sp1, y, K_sp1, m_fn, m_bar_fn, dy)\n",
        "\n",
        "# Résumé final\n",
        "import pandas as pd\n",
        "df_final_test = pd.DataFrame({\n",
        "    \"Particules ξ_n (completes)\": list(xi_n),\n",
        "    \"Poids terminaux ω̃_{n−1}\": terminal_weights,\n",
        "    \"Particules propagées ξ_s\": list(xi_s),\n",
        "    \"Poids intermédiaires ω̃_s\": intermediate_weights\n",
        "})\n",
        "\n",
        "df_final_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZORNkegH8kTH"
      },
      "source": [
        "<font color=darkblue>  D'après les tests, l'implémentation du SMC semble conforme. Les poids sont bien calculés et ajustés, et les particules sont propagées. Ce code constitue l'implémentation la plus fidèle et rigoureuse par rapport au papier. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0s6cnwC8kTI"
      },
      "source": [
        "Nous allons voir dans la prochaine implémentation, une version simplifiée de SMC, notamment au niveau du rééchantillonnage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE2XXZgb8kTI"
      },
      "source": [
        "#### <font color=darkred> Tentative d’implémentation complète de l’algorithme original </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRfKdySt8kTJ"
      },
      "source": [
        "Nous avons dans un premier temps implémenté l’algorithme $\\texttt{MCGdiff}$ tel que présenté dans l’article, en y intégrant le calcul des poids d’importance et l’échantillonnage à chaque étape du processus backward. Cette version fidèle applique la propagation des particules par Langevin, un rééchantillonnage selon les poids, ainsi qu’une pondération impliquant trois distributions normales.\n",
        "Cependant, cette version s’est révélée très coûteuse en temps de calcul, notamment en raison :\n",
        "\n",
        "- du calcul explicite de poids complexes pour chaque particule,\n",
        "- de la dimension élevée (28×28 = 784),\n",
        "- et du nombre d’étapes de reverse diffusion (100 steps).\n",
        "\n",
        "Pour des raisons pratiques, cette version complète n’a pas pu être exploitée à grande échelle. Néanmoins, elle nous a permis de valider la compréhension des éléments clés de l’algorithme : le rôle du score, la structure backward, et l’intérêt du resampling par $\\texttt{SMC}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3M3Et3I8kTJ"
      },
      "source": [
        "#### <font color=darkred> 1) Version simplifiée de </font>  $\\texttt{MCGdiff}$ <font color=darkred> sur les données MNIST </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOtywqox8kTJ"
      },
      "source": [
        "Nous avons alors mis en place une version simplifiée fidèle du processus inverse décrit dans le papier, en combinant une diffusion inversée et un guidage par le score a posteriori. Comme dans le papier, chaque particule évolue dans le temps selon une dynamique inspirée des processus de diffusion inversés (reverse DDPM), et le guidage se fait à l’aide d’un score, c’est-à-dire le gradient du log de la densité cible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xorRymGD8kTJ"
      },
      "source": [
        "Dans $\\texttt{MCGdiff}$, ce score est en principe celui de la loi posterior $p(x|y)$, qui est difficile à connaître ou à calculer explicitement. Les auteurs contournent ce problème en proposant une estimation pratique et stable via des approximations ou des modèles appris. De notre côté, pour rester dans l’esprit de l’article tout en gardant une implémentation simple, on a approximé ce score de manière analytique.\n",
        "\n",
        "On décompose le score $\\nabla \\log p(x \\mid y)$ en deux termes :\n",
        "\n",
        "$$\\nabla \\log p(x \\mid y) = \\nabla \\log p(y|x) + \\nabla \\log p(x) $$\n",
        "\n",
        "- un terme de **vraisemblance**, qui pousse les particules à se rapprocher de l’observation $y$,\n",
        "- un terme de **prior**, qui les attire vers une région probable selon notre connaissance a priori.\n",
        "\n",
        "Dans notre cas, l'observation $y$ est une image MNIST bruitée (avec un bruit gaussien $\\sigma= 0.3$), et le prior est une loi normale centrée sur la moyenne empirique des chiffres MNIST. Cette simplification évite d'entraîner un score model complexe, tout en gardant un guidage raisonnable dans l'espace des images.\n",
        "\n",
        "Ce choix d’approximation du score permet de respecter la logique du guidage dans $\\texttt{MCGdiff}$, d'obtenir une reconstruction correcte sans apprentissage supervisé et d'exécuter la méthode rapidement grâce à une formulation entièrement vectorisée.\n",
        "\n",
        "Enfin, même si on n’a pas intégré le resampling $\\texttt{SMC}$ complet du papier (qu'on a quand même codé plus haut), on conserve les éléments essentiels du schéma backward guidé, ce qui fait de notre version une bonne illustration des idées centrales de $\\texttt{MCGdiff}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4wepJR58kTJ",
        "outputId": "45149c08-c9dc-4bba-a7a4-4b07ffb859eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99it [00:07, 12.44it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x300 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Données MNIST\n",
        "transform = transforms.ToTensor()\n",
        "dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "x_clean, _ = dataset[0]\n",
        "x_clean = x_clean.unsqueeze(0)  #(1,1,28,28)\n",
        "dx = x_clean.numel()\n",
        "\n",
        "# Ajout de bruit gaussien pour simuler l'observation y\n",
        "sigma_noise = 0.3\n",
        "x_noisy = x_clean + sigma_noise * torch.randn_like(x_clean)\n",
        "y_vec = x_noisy.view(-1).numpy()\n",
        "\n",
        "# Paramètres diffusion\n",
        "num_steps = 100\n",
        "betas = np.linspace(1e-4, 0.015, num_steps)\n",
        "alphas = 1 - betas\n",
        "cum_alphas = np.cumprod(alphas)\n",
        "\n",
        "# Moyenne empirique pour prior\n",
        "mnist_mean = torch.stack([dataset[i][0] for i in range(1000)]).mean(dim=0)\n",
        "prior_mean = mnist_mean.view(-1).numpy()\n",
        "\n",
        "# Initialisation à partir de bruit total (x_T ~ N(0,I))\n",
        "n_particles = 800\n",
        "xi_s = np.random.randn(n_particles, dx)\n",
        "\n",
        "# Reverse diffusion guidée par le score\n",
        "def score_log_posterior(x, y, prior_mean, sigma_noise):\n",
        "    grad_lik = (y - x) / sigma_noise**2\n",
        "    grad_prior = -(x - prior_mean[None, :]) / 0.3**2\n",
        "    return grad_lik + grad_prior\n",
        "\n",
        "# Reverse process SCM + MCGdiff\n",
        "for s in tqdm(reversed(range(1, num_steps))):\n",
        "    alpha_s = cum_alphas[s]\n",
        "    beta_s = betas[s]\n",
        "\n",
        "    # Score log-posterior\n",
        "    score = score_log_posterior(xi_s, y_vec, prior_mean, sigma_noise)\n",
        "\n",
        "    # Update par DDPM reverse + Langevin\n",
        "    coef = 1 / np.sqrt(alphas[s])\n",
        "    xi_mean = coef * (xi_s + beta_s * score)\n",
        "    noise = np.sqrt(beta_s) * np.random.randn(*xi_s.shape) if s > 3 else 0\n",
        "    xi_s = xi_mean + noise\n",
        "\n",
        "# Reconstruction finale\n",
        "x_est = torch.tensor(np.median(xi_s, axis=0)).float().view(1, 28, 28)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
        "axs[0].imshow(x_clean.squeeze().numpy(), cmap='gray')\n",
        "axs[0].set_title(\"Image propre\")\n",
        "axs[1].imshow(x_noisy.squeeze().numpy(), cmap='gray')\n",
        "axs[1].set_title(\"Image bruitée\")\n",
        "axs[2].imshow(x_est.squeeze().numpy(), cmap='gray')\n",
        "axs[2].set_title(\"Débruitée (reverse MCGdiff)\")\n",
        "for ax in axs:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ik-qSH8kTK"
      },
      "source": [
        "<font color=darkblue> Cette approche, bien que moins rigoureuse, a donné des résultats intéressants. Elle permet notamment de visualiser une nette amélioration entre l’image bruitée et la version restaurée après 100 étapes backward.\n",
        "\n",
        "L’image débruitée garde la forme générale du 7.\n",
        "Les contours sont flous, avec une reconstruction globalement fidèle mais peu réaliste.\n",
        "La reconstruction reste assez bruitée\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n38QWKXB8kTK"
      },
      "source": [
        "####  <font color=darkred> 2) Version simplifée de </font> $\\texttt{MCGdiff}$ <font color=darkred> avec Autoencodeur convolutionnel </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpVEpByp8kTK"
      },
      "source": [
        "Dans cette version, nous avons intégré un autoencodeur convolutionnel pour approximer le prior dans la méthode MCGdiff. L’idée est d’utiliser la sortie de l’autoencodeur comme une estimation plus réaliste de la structure attendue d’une image propre de chiffre manuscrit. Le score du prior est alors estimé par la différence entre l’image actuelle et sa reconstruction par le réseau, pondérée pour guider plus fortement les particules.\n",
        "\n",
        "Les résultats sont visuellement plus convaincants que dans les versions précédentes avec prior naïf :\n",
        "L’image bruitée au centre montre une forte dégradation due au bruit (σ = 0.3), mais la forme générale reste perceptible.\n",
        "L’image reconstruite (à droite) montre une forme nette et bien définie du chiffre “3”, avec beaucoup moins de bruit résiduel.\n",
        "Le contour est mieux respecté, et l'intérieur du chiffre est plus propre, signe que l’autoencodeur a appris une bonne représentation du prior.\n",
        "\n",
        "Ce résultat confirme clairement l’intérêt d’intégrer un prior appris dans le cadre de MCGdiff. Comme le proposent les auteurs de l’article, l’idée générale est de guider la diffusion inversée non seulement par l’observation, mais aussi par une connaissance a priori de ce à quoi les données devraient ressembler. Dans l’article, cette connaissance est encodée via un modèle de score entraîné (par exemple un réseau neuronal qui approxime le gradient du log prior). Ici, nous avons choisi une alternative plus simple, mais efficace : utiliser un autoencodeur convolutionnel pré-entraîné pour jouer un rôle similaire.\n",
        "\n",
        "Concrètement, à chaque étape, on utilise la sortie de l’autoencodeur comme une estimation “propre” de l’image, et on pousse les particules à s’en rapprocher. Cette approche revient à approximer le score du prior par :\n",
        "\n",
        "$$ \\nabla \\log p(x) \\approx - \\lambda (x - \\text{AE}(x))$$\n",
        "\n",
        "où $\\lambda$ est un facteur d’intensité. Ce terme vient s’ajouter au score de la vraisemblance (provenant de l'observation), formant ainsi un score a posteriori utilisé pour guider la diffusion inversée.\n",
        "\n",
        "Ce choix présente plusieurs avantages :\n",
        "Il ne nécessite aucun apprentissage spécifique du score, ce qui réduit fortement le temps de développement.\n",
        "Il tire parti d’un réseau léger, rapide à entraîner (1 epoch suffit pour obtenir des résultats décents).\n",
        "Il offre une forme de régularisation visuelle, car l’autoencodeur a appris les structures valides des chiffres MNIST.\n",
        "\n",
        "Nous restons donc bien dans l’esprit de $\\texttt{MCGdiff}$, avec :\n",
        "- une diffusion inversée simulée via un schéma de type Langevin stochastique.\n",
        "- un guidage par un score postérieur estimé de manière accessible.\n",
        "- un resampling adaptatif via l’ESS pour éviter que les particules se concentrent trop rapidement.\n",
        "- une inertie (momentum) dans la propagation, ce qui rend la trajectoire des particules plus fluide et moins bruyante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOE1r_KX8kTL",
        "outputId": "b5b84710-c83f-45ef-cf85-6577e75c87da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training ConvAE (1 epoch): 100%|██████████| 469/469 [00:30<00:00, 15.20it/s]\n",
            "74it [00:04, 17.94it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Autoencodeur convolutionnel\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 28→14\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # 14→7\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 7 * 7, 64),  # latent dim = 64\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 32 * 7 * 7),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (32, 7, 7)),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)\n",
        "\n",
        "# Données MNIST\n",
        "transform = transforms.ToTensor()\n",
        "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "\n",
        "# Entraînement de l'autoencodeur\n",
        "ae = ConvAutoencoder()\n",
        "optimizer = optim.Adam(ae.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "ae.train()\n",
        "for images, _ in tqdm(train_loader, desc=\"Training ConvAE (1 epoch)\"):\n",
        "    optimizer.zero_grad()\n",
        "    recon = ae(images)\n",
        "    loss = criterion(recon, images)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "ae.eval()\n",
        "\n",
        "# Ensembles\n",
        "x_clean, _ = train_set[7]\n",
        "x_clean = x_clean.unsqueeze(0)\n",
        "sigma_noise = 0.3\n",
        "x_noisy = x_clean + sigma_noise * torch.randn_like(x_clean)\n",
        "\n",
        "# Paramètres MCGDiff\n",
        "num_steps = 75\n",
        "betas = torch.linspace(1e-4, 0.015, num_steps)\n",
        "alphas = 1 - betas\n",
        "cum_alphas = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "n_particles = 300\n",
        "x_particles = torch.randn(n_particles, 1, 28, 28)\n",
        "y = x_noisy.expand(n_particles, -1, -1, -1)\n",
        "velocity = torch.zeros_like(x_particles)\n",
        "\n",
        "# 6. Fonctions auxiliaires\n",
        "def log_likelihood(x, y, sigma):\n",
        "    return -((x - y)**2).view(len(x), -1).sum(dim=1) / (2 * sigma**2)\n",
        "\n",
        "def resample(particles, weights):\n",
        "    probs = torch.softmax(weights, dim=0)\n",
        "    indices = torch.multinomial(probs, len(particles), replacement=True)\n",
        "    return particles[indices]\n",
        "\n",
        "# Boucle MCGDiff avec prior AE\n",
        "x = x_particles.clone()\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(reversed(range(1, num_steps))):\n",
        "        alpha_t = cum_alphas[i]\n",
        "        beta_t = betas[i]\n",
        "\n",
        "        # Gradient log-posterior : likelihood + prior appris\n",
        "        grad_likelihood = 3 * (y - x) / sigma_noise**2\n",
        "        x_autoencoded = ae(x)\n",
        "        grad_prior = -5 * (x - x_autoencoded) / 0.3**2  # poids du prior augmenté\n",
        "        grad_log_post = grad_likelihood + grad_prior\n",
        "\n",
        "        # Langevin + momentum\n",
        "        x_mean = (1 / torch.sqrt(alphas[i])) * (x + beta_t * grad_log_post)\n",
        "        velocity = 0.9 * velocity + 0.1 * (x_mean - x)\n",
        "        x = x_mean + torch.sqrt(beta_t) * torch.randn_like(x) + velocity\n",
        "\n",
        "        # Rééchantillonnage adaptatif (ESS)\n",
        "        ll = log_likelihood(x, y, sigma_noise)\n",
        "        probs = torch.softmax(ll, dim=0)\n",
        "        ess = 1 / (probs**2).sum()\n",
        "        if ess < 0.5 * n_particles:\n",
        "            x = resample(x, ll)\n",
        "\n",
        "# Reconstruction finale\n",
        "x_est = x.mean(dim=0)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axs[0].imshow(x_clean.squeeze(), cmap='gray')\n",
        "axs[0].set_title(\"Image propre\")\n",
        "axs[1].imshow(x_noisy.squeeze(), cmap='gray')\n",
        "axs[1].set_title(\"Image bruitée\")\n",
        "axs[2].imshow(x_est.squeeze().detach(), cmap='gray')\n",
        "axs[2].set_title(\"Débruitée (ConvAE Prior)\")\n",
        "for ax in axs:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OzgavaE8kTM"
      },
      "source": [
        "<font color=darkblue> Cette version montre qu’il est possible d’atteindre une qualité de reconstruction élevée avec un modèle relativement simple. L’autoencodeur apprend efficacement les structures attendues des chiffres et agit comme un prior informatif, tout en s’intégrant naturellement dans la logique de MCGdiff. Cela en fait une approche à la fois pragmatique et fidèle aux idées de l’article, adaptée à des projets rapides mais ambitieux. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsA27Ius8kTN"
      },
      "source": [
        "####  <font color=darkred> Bilan sur les versions testées </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5E1bg4J8kTN"
      },
      "source": [
        "Par rapport à la version 1, où le prior était la moyenne empirique des images MNIST, l’utilisation de l’autoencodeur convolutionnel dans la version 2 améliore clairement la qualité de la reconstruction :\n",
        "\n",
        "En effet, les formes sont plus précises : les contours du chiffre sont plus nets et mieux définis. L’autoencodeur apporte une vraie information structurelle sur ce à quoi “ressemble” une image valide.\n",
        "\n",
        "Le bruit résiduel est réduit : le bruit parasite est bien atténué, sans pour autant lisser ou déformer le chiffre comme dans certaines approches trop brutales.\n",
        "- Adaptabilité : le prior appris s’ajuste mieux à des cas variés qu’une moyenne fixe, ce qui le rend plus robuste.\n",
        "\n",
        "Finalement, les résultats “ressemblent” beaucoup plus à une vraie image MNIST propre, même en présence de fort bruit.\n",
        "\n",
        "En revanche, le score basé sur un autoencodeur n’est pas aussi “justifié théoriquement” qu’un modèle de score entraîné par score matching, comme dans l’article. Mais il reste une approximation tout à fait raisonnable dans un cadre simplifié. De plus, il existe un coût d’entraînement initial (même si faible), contrairement à la version analytique.\n",
        "\n",
        "En résumé, la version 2 (avec prior appris) permet d’améliorer significativement les résultats, tout en gardant une structure algorithmique fidèle au papier. C’est une bonne démonstration de l’intérêt d’intégrer de l’apprentissage léger dans une méthode probabiliste de type $\\texttt{MCGdiff}$."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}